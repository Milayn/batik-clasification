{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-4.9.4-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting absl-py (from tensorflow_datasets)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting click (from tensorflow_datasets)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting dm-tree (from tensorflow_datasets)\n",
      "  Downloading dm_tree-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
      "Collecting etils>=0.9.0 (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets)\n",
      "  Downloading etils-1.7.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow_datasets) (1.26.4)\n",
      "Collecting promise (from tensorflow_datasets)\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting protobuf>=3.20 (from tensorflow_datasets)\n",
      "  Downloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: psutil in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow_datasets) (5.9.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow_datasets) (2.31.0)\n",
      "Collecting tensorflow-metadata (from tensorflow_datasets)\n",
      "  Downloading tensorflow_metadata-1.14.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting termcolor (from tensorflow_datasets)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting toml (from tensorflow_datasets)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting tqdm (from tensorflow_datasets)\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wrapt (from tensorflow_datasets)\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting array-record>=0.5.0 (from tensorflow_datasets)\n",
      "  Downloading array_record-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (699 bytes)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (2024.3.1)\n",
      "Collecting importlib_resources (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets)\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing_extensions in /home/codespace/.local/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (4.10.0)\n",
      "Collecting zipp (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets)\n",
      "  Downloading zipp-3.18.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (2024.2.2)\n",
      "Requirement already satisfied: six in /home/codespace/.local/lib/python3.10/site-packages (from promise->tensorflow_datasets) (1.16.0)\n",
      "Collecting absl-py (from tensorflow_datasets)\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0 (from tensorflow-metadata->tensorflow_datasets)\n",
      "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting protobuf>=3.20 (from tensorflow_datasets)\n",
      "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
      "Downloading tensorflow_datasets-4.9.4-py3-none-any.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading array_record-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading etils-1.7.0-py3-none-any.whl (152 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dm_tree-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.8/152.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_metadata-1.14.0-py3-none-any.whl (28 kB)\n",
      "Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.1/229.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading zipp-3.18.1-py3-none-any.whl (8.2 kB)\n",
      "Building wheels for collected packages: promise\n",
      "  Building wheel for promise (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21483 sha256=cb62ab4df7ff7b929b8aa4175a1612b8063bdc27a2c12f5f4acc8a267c39af0a\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/54/4e/28/3ed0e1c8a752867445bab994d2340724928aa3ab059c57c8db\n",
      "Successfully built promise\n",
      "Installing collected packages: dm-tree, zipp, wrapt, tqdm, toml, termcolor, protobuf, promise, importlib_resources, etils, click, absl-py, googleapis-common-protos, tensorflow-metadata, array-record, tensorflow_datasets\n",
      "Successfully installed absl-py-1.4.0 array-record-0.5.1 click-8.1.7 dm-tree-0.1.8 etils-1.7.0 googleapis-common-protos-1.63.0 importlib_resources-6.4.0 promise-2.3 protobuf-3.20.3 tensorflow-metadata-1.14.0 tensorflow_datasets-4.9.4 termcolor-2.4.0 toml-0.10.2 tqdm-4.66.2 wrapt-1.16.0 zipp-3.18.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.5.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow)\n",
      "  Downloading h5py-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow)\n",
      "  Downloading keras-3.1.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.36.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Using cached wheel-0.43.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting rich (from keras>=3.0.0->tensorflow)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow)\n",
      "  Downloading namex-0.0.7-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow)\n",
      "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Downloading werkzeug-3.0.2-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/codespace/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.0.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.1.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.36.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.0.2-py3-none-any.whl (226 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.8/226.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached wheel-0.43.0-py3-none-any.whl (65 kB)\n",
      "Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wheel, werkzeug, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, opt-einsum, ml-dtypes, mdurl, markdown, h5py, grpcio, google-pasta, gast, tensorboard, markdown-it-py, astunparse, rich, keras, tensorflow\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-24.3.25 gast-0.5.4 google-pasta-0.2.0 grpcio-1.62.1 h5py-3.10.0 keras-3.1.1 libclang-18.1.1 markdown-3.6 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.3.2 namex-0.0.7 opt-einsum-3.3.0 optree-0.11.0 rich-13.7.1 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-io-gcs-filesystem-0.36.0 werkzeug-3.0.2 wheel-0.43.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow_datasets\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-learn version is:  1.4.1.post1\n",
      "Tensorflow version is:  2.16.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "(\"Python version is\", sys.version)\n",
    "import sklearn\n",
    "print(\"Scikit-learn version is: \", sklearn.__version__)\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version is: \", tf.__version__)\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case Ketika shuffle=False, random_state=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 240 files belonging to 60 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-06 09:36:26.095543: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 521ms/step - accuracy: 0.0165 - loss: 0.8281 - val_accuracy: 0.0513 - val_loss: 0.1797\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - accuracy: 0.0878 - loss: 0.1848 - val_accuracy: 0.0513 - val_loss: 0.1426\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - accuracy: 0.1265 - loss: 0.1433 - val_accuracy: 0.0769 - val_loss: 0.1311\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - accuracy: 0.2743 - loss: 0.1132 - val_accuracy: 0.1795 - val_loss: 0.1222\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - accuracy: 0.4124 - loss: 0.0796 - val_accuracy: 0.2308 - val_loss: 0.1088\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - accuracy: 0.5085 - loss: 0.0532 - val_accuracy: 0.2821 - val_loss: 0.0952\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 182ms/step - accuracy: 0.6885 - loss: 0.0409 - val_accuracy: 0.4615 - val_loss: 0.0859\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - accuracy: 0.8349 - loss: 0.0283 - val_accuracy: 0.6154 - val_loss: 0.0758\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - accuracy: 0.9170 - loss: 0.0199 - val_accuracy: 0.6410 - val_loss: 0.0719\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.9661 - loss: 0.0172 - val_accuracy: 0.7692 - val_loss: 0.0664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/model_fold_1.h5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
      "Training for fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 530ms/step - accuracy: 0.0131 - loss: 0.9207 - val_accuracy: 0.0000e+00 - val_loss: 0.1904\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 169ms/step - accuracy: 0.0991 - loss: 0.1660 - val_accuracy: 0.2051 - val_loss: 0.1539\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 193ms/step - accuracy: 0.2751 - loss: 0.1294 - val_accuracy: 0.1282 - val_loss: 0.1476\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - accuracy: 0.3360 - loss: 0.0998 - val_accuracy: 0.2051 - val_loss: 0.1076\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - accuracy: 0.4751 - loss: 0.0628 - val_accuracy: 0.4103 - val_loss: 0.0784\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - accuracy: 0.6828 - loss: 0.0346 - val_accuracy: 0.6410 - val_loss: 0.0581\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - accuracy: 0.9005 - loss: 0.0216 - val_accuracy: 0.7949 - val_loss: 0.0498\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 176ms/step - accuracy: 0.9626 - loss: 0.0155 - val_accuracy: 0.8205 - val_loss: 0.0496\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - accuracy: 0.9978 - loss: 0.0091 - val_accuracy: 0.8205 - val_loss: 0.0505\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - accuracy: 0.9948 - loss: 0.0067 - val_accuracy: 0.8205 - val_loss: 0.0513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/model_fold_2.h5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
      "Training for fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 481ms/step - accuracy: 0.0277 - loss: 0.7713 - val_accuracy: 0.0263 - val_loss: 0.1775\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.0204 - loss: 0.1759 - val_accuracy: 0.0263 - val_loss: 0.1654\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 196ms/step - accuracy: 0.1925 - loss: 0.1423 - val_accuracy: 0.0526 - val_loss: 0.1542\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - accuracy: 0.3621 - loss: 0.1185 - val_accuracy: 0.1579 - val_loss: 0.1172\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 186ms/step - accuracy: 0.4414 - loss: 0.0869 - val_accuracy: 0.2632 - val_loss: 0.0860\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 177ms/step - accuracy: 0.6067 - loss: 0.0527 - val_accuracy: 0.3947 - val_loss: 0.0646\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - accuracy: 0.7242 - loss: 0.0374 - val_accuracy: 0.4211 - val_loss: 0.0465\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - accuracy: 0.8577 - loss: 0.0231 - val_accuracy: 0.7368 - val_loss: 0.0385\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 175ms/step - accuracy: 0.9723 - loss: 0.0177 - val_accuracy: 0.7368 - val_loss: 0.0345\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - accuracy: 0.9792 - loss: 0.0145 - val_accuracy: 0.8421 - val_loss: 0.0295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/model_fold_3.h5\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7feb7a8170a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7feb7a8170a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/stepWARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7feb7a8170a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7feb7a8170a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
      "Training for fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 475ms/step - accuracy: 0.0507 - loss: 0.6302 - val_accuracy: 0.0000e+00 - val_loss: 0.1701\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - accuracy: 0.0737 - loss: 0.1606 - val_accuracy: 0.0263 - val_loss: 0.1759\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 200ms/step - accuracy: 0.1470 - loss: 0.1344 - val_accuracy: 0.1316 - val_loss: 0.1553\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.3599 - loss: 0.0969 - val_accuracy: 0.2632 - val_loss: 0.1286\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.5941 - loss: 0.0635 - val_accuracy: 0.3947 - val_loss: 0.1050\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.7736 - loss: 0.0396 - val_accuracy: 0.4737 - val_loss: 0.0799\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step - accuracy: 0.8690 - loss: 0.0240 - val_accuracy: 0.6053 - val_loss: 0.0624\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.9020 - loss: 0.0230 - val_accuracy: 0.6842 - val_loss: 0.0515\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 180ms/step - accuracy: 0.9601 - loss: 0.0141 - val_accuracy: 0.7632 - val_loss: 0.0431\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 168ms/step - accuracy: 0.9610 - loss: 0.0106 - val_accuracy: 0.7632 - val_loss: 0.0403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/model_fold_4.h5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
      "Training for fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 496ms/step - accuracy: 0.0000e+00 - loss: 0.7682 - val_accuracy: 0.0526 - val_loss: 0.1748\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 173ms/step - accuracy: 0.0967 - loss: 0.1594 - val_accuracy: 0.1053 - val_loss: 0.2064\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - accuracy: 0.2979 - loss: 0.1454 - val_accuracy: 0.2105 - val_loss: 0.2002\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - accuracy: 0.4991 - loss: 0.0891 - val_accuracy: 0.3684 - val_loss: 0.1633\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 170ms/step - accuracy: 0.7849 - loss: 0.0496 - val_accuracy: 0.4737 - val_loss: 0.1320\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 180ms/step - accuracy: 0.7853 - loss: 0.0391 - val_accuracy: 0.5263 - val_loss: 0.1085\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - accuracy: 0.9280 - loss: 0.0151 - val_accuracy: 0.7105 - val_loss: 0.0889\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 180ms/step - accuracy: 0.9718 - loss: 0.0106 - val_accuracy: 0.7368 - val_loss: 0.0785\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - accuracy: 0.9679 - loss: 0.0083 - val_accuracy: 0.7632 - val_loss: 0.0696\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - accuracy: 0.9948 - loss: 0.0056 - val_accuracy: 0.7895 - val_loss: 0.0636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/model_fold_5.h5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
      "Accuracy for fold 1: 0.3958333333333333\n",
      "Accuracy for fold 2: 0.6458333333333334\n",
      "Accuracy for fold 3: 0.6041666666666666\n",
      "Accuracy for fold 4: 0.7083333333333334\n",
      "Accuracy for fold 5: 0.75\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Load your image dataset and preprocessing here\n",
    "# Assume X is your image data and Y is your labels\n",
    "# Modify this part according to your image dataset loading and preprocessing\n",
    "\n",
    "# Define your image data (X) and labels (Y) here\n",
    "# Example: X = ... # Load images using some method (e.g., tf.keras.preprocessing.image_dataset_from_directory)\n",
    "X = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"dataset/data\",\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    color_mode='rgb',  # Mengatur mode warna menjadi grayscale\n",
    "    batch_size=32,\n",
    "    image_size=(52, 52),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    ")\n",
    "# Example: Y = ... # Load labels (may need to be encoded)\n",
    "def extract_labels(image, label):\n",
    "    return label\n",
    "\n",
    "# Map the dataset to extract labels\n",
    "Y = X.map(extract_labels)\n",
    "\n",
    "# Split data into train and test sets\n",
    "# Convert dataset to numpy arrays\n",
    "X_list = []\n",
    "Y_list = []\n",
    "for images, labels in X.as_numpy_iterator():\n",
    "    X_list.extend(images)\n",
    "    Y_list.extend(labels)\n",
    "X = np.array(X_list)\n",
    "Y = np.array(Y_list)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=None)\n",
    "\n",
    "# Convert labels to one-hot vectors\n",
    "Y_train = to_categorical(Y_train, num_classes=60)\n",
    "Y_test = to_categorical(Y_test, num_classes=60)\n",
    "\n",
    "# Define the ResNet50 model\n",
    "def build_resnet50_model():\n",
    "    # Membuat base model ResNet50 tanpa lapisan Fully Connected terakhir\n",
    "    base_model = ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(52, 52, 3),\n",
    "    )\n",
    "\n",
    "    # Menghentikan layer-layer yang ada pada base model agar tidak ter-update selama pelatihan\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Membangun model dengan menambahkan lapisan kustom di atas base model\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    predictions = Dense(60, activation='softmax')(x)\n",
    "\n",
    "    # Membuat model gabungan\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Initialize k-Fold\n",
    "kf = KFold(n_splits=5, shuffle=False, random_state=None)\n",
    "\n",
    "# Execute K-fold cross-validation\n",
    "fold_no = 1\n",
    "acc_per_fold = [] # Save accuracy from each fold\n",
    "\n",
    "# Train the model for each split (fold)\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    print('Training for fold', fold_no)\n",
    "\n",
    "    # Get train and test data for this fold\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[test_index]\n",
    "    Y_train_fold, Y_val_fold = Y_train[train_index], Y_train[test_index]\n",
    "\n",
    "    # Build the model\n",
    "    model = build_resnet50_model()\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train_fold, Y_train_fold, epochs=10, validation_data=(X_val_fold, Y_val_fold))\n",
    "\n",
    "    # Save the model\n",
    "    model_save_path = f\"models/model_fold_{fold_no}.h5\"\n",
    "    model.save(model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_binary = (y_pred >= 0.5).astype(int)\n",
    "    accuracy = accuracy_score(Y_test, y_pred_binary)\n",
    "    acc_per_fold.append(accuracy)\n",
    "\n",
    "    fold_no += 1\n",
    "\n",
    "# Print accuracy for each fold\n",
    "for i, acc in enumerate(acc_per_fold, 1):\n",
    "    print(f'Accuracy for fold {i}: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case Ketika shuffle=False, random_state=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 240 files belonging to 60 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-06 09:40:07.204000: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 475ms/step - accuracy: 0.0282 - loss: 0.7471 - val_accuracy: 0.0513 - val_loss: 0.1168\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - accuracy: 0.0648 - loss: 0.1393 - val_accuracy: 0.1026 - val_loss: 0.1252\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 186ms/step - accuracy: 0.2104 - loss: 0.1180 - val_accuracy: 0.1538 - val_loss: 0.1185\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - accuracy: 0.4289 - loss: 0.0858 - val_accuracy: 0.2564 - val_loss: 0.1027\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.6267 - loss: 0.0533 - val_accuracy: 0.3846 - val_loss: 0.0789\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 174ms/step - accuracy: 0.7657 - loss: 0.0373 - val_accuracy: 0.5128 - val_loss: 0.0560\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 168ms/step - accuracy: 0.8670 - loss: 0.0231 - val_accuracy: 0.6410 - val_loss: 0.0424\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step - accuracy: 0.9452 - loss: 0.0178 - val_accuracy: 0.7436 - val_loss: 0.0337\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step - accuracy: 0.9596 - loss: 0.0124 - val_accuracy: 0.7692 - val_loss: 0.0275\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 170ms/step - accuracy: 0.9765 - loss: 0.0085 - val_accuracy: 0.8205 - val_loss: 0.0239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/model_fold_1.h5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
      "Training for fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 477ms/step - accuracy: 0.0000e+00 - loss: 0.7484 - val_accuracy: 0.0256 - val_loss: 0.1702\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - accuracy: 0.0557 - loss: 0.1891 - val_accuracy: 0.1026 - val_loss: 0.1856\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 174ms/step - accuracy: 0.2608 - loss: 0.1459 - val_accuracy: 0.3077 - val_loss: 0.1436\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - accuracy: 0.5380 - loss: 0.0961 - val_accuracy: 0.3846 - val_loss: 0.0998\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 173ms/step - accuracy: 0.5885 - loss: 0.0591 - val_accuracy: 0.4872 - val_loss: 0.0770\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 168ms/step - accuracy: 0.8479 - loss: 0.0304 - val_accuracy: 0.5897 - val_loss: 0.0649\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 169ms/step - accuracy: 0.9187 - loss: 0.0190 - val_accuracy: 0.7436 - val_loss: 0.0486\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - accuracy: 0.9487 - loss: 0.0121 - val_accuracy: 0.7949 - val_loss: 0.0380\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - accuracy: 0.9783 - loss: 0.0096 - val_accuracy: 0.8718 - val_loss: 0.0249\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - accuracy: 0.9609 - loss: 0.0089 - val_accuracy: 0.8462 - val_loss: 0.0164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/model_fold_2.h5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
      "Training for fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 480ms/step - accuracy: 0.0130 - loss: 0.8194 - val_accuracy: 0.0000e+00 - val_loss: 0.1548\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 180ms/step - accuracy: 0.0616 - loss: 0.1602 - val_accuracy: 0.0263 - val_loss: 0.1501\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 168ms/step - accuracy: 0.1630 - loss: 0.1455 - val_accuracy: 0.1579 - val_loss: 0.1323\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - accuracy: 0.3920 - loss: 0.0867 - val_accuracy: 0.3684 - val_loss: 0.1145\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step - accuracy: 0.6192 - loss: 0.0536 - val_accuracy: 0.3947 - val_loss: 0.1056\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - accuracy: 0.7714 - loss: 0.0318 - val_accuracy: 0.5526 - val_loss: 0.0979\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - accuracy: 0.9016 - loss: 0.0224 - val_accuracy: 0.5526 - val_loss: 0.0950\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - accuracy: 0.9180 - loss: 0.0141 - val_accuracy: 0.5789 - val_loss: 0.0944\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - accuracy: 0.9740 - loss: 0.0103 - val_accuracy: 0.5789 - val_loss: 0.0906\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.6579 - val_loss: 0.0865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/model_fold_3.h5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
      "Training for fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 469ms/step - accuracy: 0.0364 - loss: 0.9937 - val_accuracy: 0.0000e+00 - val_loss: 0.1885\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 198ms/step - accuracy: 0.0251 - loss: 0.1706 - val_accuracy: 0.0789 - val_loss: 0.1711\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 168ms/step - accuracy: 0.1180 - loss: 0.1588 - val_accuracy: 0.0789 - val_loss: 0.1501\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - accuracy: 0.2467 - loss: 0.1238 - val_accuracy: 0.1842 - val_loss: 0.1201\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - accuracy: 0.4887 - loss: 0.0771 - val_accuracy: 0.5526 - val_loss: 0.0958\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 173ms/step - accuracy: 0.6829 - loss: 0.0543 - val_accuracy: 0.6579 - val_loss: 0.0860\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 169ms/step - accuracy: 0.7992 - loss: 0.0356 - val_accuracy: 0.7105 - val_loss: 0.0711\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - accuracy: 0.8894 - loss: 0.0214 - val_accuracy: 0.7895 - val_loss: 0.0583\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 168ms/step - accuracy: 0.9705 - loss: 0.0129 - val_accuracy: 0.8158 - val_loss: 0.0544\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - accuracy: 0.9870 - loss: 0.0092 - val_accuracy: 0.8421 - val_loss: 0.0469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/model_fold_4.h5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
      "Training for fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 463ms/step - accuracy: 0.0130 - loss: 0.6912 - val_accuracy: 0.0526 - val_loss: 0.1704\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.0776 - loss: 0.1796 - val_accuracy: 0.1053 - val_loss: 0.1568\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 214ms/step - accuracy: 0.1817 - loss: 0.1656 - val_accuracy: 0.0789 - val_loss: 0.1532\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step - accuracy: 0.3529 - loss: 0.1037 - val_accuracy: 0.2368 - val_loss: 0.1315\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.5485 - loss: 0.0747 - val_accuracy: 0.2368 - val_loss: 0.1037\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 173ms/step - accuracy: 0.7203 - loss: 0.0440 - val_accuracy: 0.4474 - val_loss: 0.0848\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - accuracy: 0.8157 - loss: 0.0288 - val_accuracy: 0.5789 - val_loss: 0.0696\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.9193 - loss: 0.0157 - val_accuracy: 0.6842 - val_loss: 0.0626\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 170ms/step - accuracy: 0.9705 - loss: 0.0112 - val_accuracy: 0.6842 - val_loss: 0.0548\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.9965 - loss: 0.0072 - val_accuracy: 0.6579 - val_loss: 0.0525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/model_fold_5.h5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
      "Accuracy for fold 1: 0.6666666666666666\n",
      "Accuracy for fold 2: 0.7916666666666666\n",
      "Accuracy for fold 3: 0.6875\n",
      "Accuracy for fold 4: 0.6458333333333334\n",
      "Accuracy for fold 5: 0.6875\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Load your image dataset and preprocessing here\n",
    "# Assume X is your image data and Y is your labels\n",
    "# Modify this part according to your image dataset loading and preprocessing\n",
    "\n",
    "# Define your image data (X) and labels (Y) here\n",
    "# Example: X = ... # Load images using some method (e.g., tf.keras.preprocessing.image_dataset_from_directory)\n",
    "X = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"dataset/data\",\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    color_mode='rgb',  # Mengatur mode warna menjadi grayscale\n",
    "    batch_size=32,\n",
    "    image_size=(52, 52),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    ")\n",
    "# Example: Y = ... # Load labels (may need to be encoded)\n",
    "def extract_labels(image, label):\n",
    "    return label\n",
    "\n",
    "# Map the dataset to extract labels\n",
    "Y = X.map(extract_labels)\n",
    "\n",
    "# Split data into train and test sets\n",
    "# Convert dataset to numpy arrays\n",
    "X_list = []\n",
    "Y_list = []\n",
    "for images, labels in X.as_numpy_iterator():\n",
    "    X_list.extend(images)\n",
    "    Y_list.extend(labels)\n",
    "X = np.array(X_list)\n",
    "Y = np.array(Y_list)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=None)\n",
    "\n",
    "# Convert labels to one-hot vectors\n",
    "Y_train = to_categorical(Y_train, num_classes=60)\n",
    "Y_test = to_categorical(Y_test, num_classes=60)\n",
    "\n",
    "# Define the ResNet50 model\n",
    "def build_resnet50_model():\n",
    "    # Membuat base model ResNet50 tanpa lapisan Fully Connected terakhir\n",
    "    base_model = ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(52, 52, 3),\n",
    "    )\n",
    "\n",
    "    # Menghentikan layer-layer yang ada pada base model agar tidak ter-update selama pelatihan\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Membangun model dengan menambahkan lapisan kustom di atas base model\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    predictions = Dense(60, activation='softmax')(x)\n",
    "\n",
    "    # Membuat model gabungan\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Initialize k-Fold\n",
    "kf = KFold(n_splits=5, shuffle=False, random_state=None)\n",
    "\n",
    "# Execute K-fold cross-validation\n",
    "fold_no = 1\n",
    "acc_per_fold = [] # Save accuracy from each fold\n",
    "\n",
    "# Train the model for each split (fold)\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    print('Training for fold', fold_no)\n",
    "\n",
    "    # Get train and test data for this fold\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[test_index]\n",
    "    Y_train_fold, Y_val_fold = Y_train[train_index], Y_train[test_index]\n",
    "\n",
    "    # Build the model\n",
    "    model = build_resnet50_model()\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train_fold, Y_train_fold, epochs=10, validation_data=(X_val_fold, Y_val_fold))\n",
    "\n",
    "    # Save the model\n",
    "    model_save_path = f\"models/model_fold_{fold_no}.h5\"\n",
    "    model.save(model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_binary = (y_pred >= 0.5).astype(int)\n",
    "    accuracy = accuracy_score(Y_test, y_pred_binary)\n",
    "    acc_per_fold.append(accuracy)\n",
    "\n",
    "    fold_no += 1\n",
    "\n",
    "# Print accuracy for each fold\n",
    "for i, acc in enumerate(acc_per_fold, 1):\n",
    "    print(f'Accuracy for fold {i}: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case Ketika shuffle=True, random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 240 files belonging to 60 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-06 09:42:58.996397: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 475ms/step - accuracy: 0.0365 - loss: 0.8944 - val_accuracy: 0.0513 - val_loss: 0.2645\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - accuracy: 0.0274 - loss: 0.1846 - val_accuracy: 0.0513 - val_loss: 0.2342\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.1386 - loss: 0.1505 - val_accuracy: 0.1026 - val_loss: 0.2197\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step - accuracy: 0.2352 - loss: 0.1166 - val_accuracy: 0.2051 - val_loss: 0.1811\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 176ms/step - accuracy: 0.4372 - loss: 0.0783 - val_accuracy: 0.2308 - val_loss: 0.1432\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - accuracy: 0.5398 - loss: 0.0612 - val_accuracy: 0.4103 - val_loss: 0.1088\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 169ms/step - accuracy: 0.6715 - loss: 0.0425 - val_accuracy: 0.4615 - val_loss: 0.0849\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - accuracy: 0.8557 - loss: 0.0267 - val_accuracy: 0.5641 - val_loss: 0.0722\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - accuracy: 0.9231 - loss: 0.0225 - val_accuracy: 0.7179 - val_loss: 0.0605\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 169ms/step - accuracy: 0.9835 - loss: 0.0148 - val_accuracy: 0.7179 - val_loss: 0.0529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/model_fold_1.h5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
      "Training for fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 472ms/step - accuracy: 0.0204 - loss: 0.8061 - val_accuracy: 0.0513 - val_loss: 0.1472\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 186ms/step - accuracy: 0.0782 - loss: 0.1584 - val_accuracy: 0.0769 - val_loss: 0.1553\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - accuracy: 0.1443 - loss: 0.1391 - val_accuracy: 0.1795 - val_loss: 0.1454\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 168ms/step - accuracy: 0.3277 - loss: 0.1157 - val_accuracy: 0.2564 - val_loss: 0.1117\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 178ms/step - accuracy: 0.4716 - loss: 0.0773 - val_accuracy: 0.3590 - val_loss: 0.0779\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - accuracy: 0.6176 - loss: 0.0520 - val_accuracy: 0.4615 - val_loss: 0.0555\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - accuracy: 0.7849 - loss: 0.0310 - val_accuracy: 0.6410 - val_loss: 0.0416\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - accuracy: 0.8853 - loss: 0.0197 - val_accuracy: 0.6667 - val_loss: 0.0356\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - accuracy: 0.9492 - loss: 0.0153 - val_accuracy: 0.6667 - val_loss: 0.0354\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 174ms/step - accuracy: 0.9735 - loss: 0.0113 - val_accuracy: 0.7179 - val_loss: 0.0326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/model_fold_2.h5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2s/step\n",
      "Training for fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 482ms/step - accuracy: 0.0147 - loss: 0.8699 - val_accuracy: 0.0263 - val_loss: 0.1832\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - accuracy: 0.0685 - loss: 0.1763 - val_accuracy: 0.0263 - val_loss: 0.1708\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 0.1570 - loss: 0.1466 - val_accuracy: 0.2632 - val_loss: 0.1427\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - accuracy: 0.4119 - loss: 0.1007 - val_accuracy: 0.3421 - val_loss: 0.0979\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 0.6041 - loss: 0.0511 - val_accuracy: 0.5263 - val_loss: 0.0597\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 168ms/step - accuracy: 0.7675 - loss: 0.0334 - val_accuracy: 0.5789 - val_loss: 0.0447\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.8699 - loss: 0.0206 - val_accuracy: 0.6842 - val_loss: 0.0397\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - accuracy: 0.9692 - loss: 0.0097 - val_accuracy: 0.7632 - val_loss: 0.0337\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - accuracy: 0.9792 - loss: 0.0074 - val_accuracy: 0.7368 - val_loss: 0.0254\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 169ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.8158 - val_loss: 0.0272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/model_fold_3.h5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
      "Training for fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 473ms/step - accuracy: 0.0260 - loss: 0.8599 - val_accuracy: 0.0000e+00 - val_loss: 0.2552\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - accuracy: 0.0126 - loss: 0.2101 - val_accuracy: 0.0263 - val_loss: 0.1576\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 0.0603 - loss: 0.1268 - val_accuracy: 0.1316 - val_loss: 0.1584\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.2693 - loss: 0.1087 - val_accuracy: 0.2632 - val_loss: 0.1365\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 171ms/step - accuracy: 0.4132 - loss: 0.0778 - val_accuracy: 0.3421 - val_loss: 0.1085\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - accuracy: 0.6396 - loss: 0.0541 - val_accuracy: 0.4474 - val_loss: 0.0836\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - accuracy: 0.7866 - loss: 0.0341 - val_accuracy: 0.4737 - val_loss: 0.0645\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - accuracy: 0.8526 - loss: 0.0274 - val_accuracy: 0.5789 - val_loss: 0.0505\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - accuracy: 0.9636 - loss: 0.0174 - val_accuracy: 0.7632 - val_loss: 0.0419\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - accuracy: 0.9788 - loss: 0.0158 - val_accuracy: 0.7632 - val_loss: 0.0372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/model_fold_4.h5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
      "Training for fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 473ms/step - accuracy: 0.0052 - loss: 0.7166 - val_accuracy: 0.0263 - val_loss: 0.1680\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.0832 - loss: 0.1592 - val_accuracy: 0.0789 - val_loss: 0.1838\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - accuracy: 0.2012 - loss: 0.1419 - val_accuracy: 0.1053 - val_loss: 0.1767\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 171ms/step - accuracy: 0.3907 - loss: 0.1027 - val_accuracy: 0.2105 - val_loss: 0.1560\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - accuracy: 0.5919 - loss: 0.0692 - val_accuracy: 0.3158 - val_loss: 0.1281\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - accuracy: 0.7259 - loss: 0.0403 - val_accuracy: 0.3684 - val_loss: 0.0881\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 168ms/step - accuracy: 0.8495 - loss: 0.0248 - val_accuracy: 0.5263 - val_loss: 0.0586\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.9098 - loss: 0.0158 - val_accuracy: 0.6053 - val_loss: 0.0411\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 171ms/step - accuracy: 0.9736 - loss: 0.0106 - val_accuracy: 0.6842 - val_loss: 0.0338\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.9922 - loss: 0.0077 - val_accuracy: 0.7632 - val_loss: 0.0290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/model_fold_5.h5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
      "Accuracy for fold 1: 0.3958333333333333\n",
      "Accuracy for fold 2: 0.3958333333333333\n",
      "Accuracy for fold 3: 0.6666666666666666\n",
      "Accuracy for fold 4: 0.4166666666666667\n",
      "Accuracy for fold 5: 0.5208333333333334\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Load your image dataset and preprocessing here\n",
    "# Assume X is your image data and Y is your labels\n",
    "# Modify this part according to your image dataset loading and preprocessing\n",
    "\n",
    "# Define your image data (X) and labels (Y) here\n",
    "# Example: X = ... # Load images using some method (e.g., tf.keras.preprocessing.image_dataset_from_directory)\n",
    "X = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"dataset/data\",\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    color_mode='rgb',  # Mengatur mode warna menjadi grayscale\n",
    "    batch_size=32,\n",
    "    image_size=(52, 52),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    ")\n",
    "# Example: Y = ... # Load labels (may need to be encoded)\n",
    "def extract_labels(image, label):\n",
    "    return label\n",
    "\n",
    "# Map the dataset to extract labels\n",
    "Y = X.map(extract_labels)\n",
    "\n",
    "# Split data into train and test sets\n",
    "# Convert dataset to numpy arrays\n",
    "X_list = []\n",
    "Y_list = []\n",
    "for images, labels in X.as_numpy_iterator():\n",
    "    X_list.extend(images)\n",
    "    Y_list.extend(labels)\n",
    "X = np.array(X_list)\n",
    "Y = np.array(Y_list)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to one-hot vectors\n",
    "Y_train = to_categorical(Y_train, num_classes=60)\n",
    "Y_test = to_categorical(Y_test, num_classes=60)\n",
    "\n",
    "# Define the ResNet50 model\n",
    "def build_resnet50_model():\n",
    "    # Membuat base model ResNet50 tanpa lapisan Fully Connected terakhir\n",
    "    base_model = ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(52, 52, 3),\n",
    "    )\n",
    "\n",
    "    # Menghentikan layer-layer yang ada pada base model agar tidak ter-update selama pelatihan\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Membangun model dengan menambahkan lapisan kustom di atas base model\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    predictions = Dense(60, activation='softmax')(x)\n",
    "\n",
    "    # Membuat model gabungan\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Initialize k-Fold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Execute K-fold cross-validation\n",
    "fold_no = 1\n",
    "acc_per_fold = [] # Save accuracy from each fold\n",
    "\n",
    "# Train the model for each split (fold)\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    print('Training for fold', fold_no)\n",
    "\n",
    "    # Get train and test data for this fold\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[test_index]\n",
    "    Y_train_fold, Y_val_fold = Y_train[train_index], Y_train[test_index]\n",
    "\n",
    "    # Build the model\n",
    "    model = build_resnet50_model()\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train_fold, Y_train_fold, epochs=10, validation_data=(X_val_fold, Y_val_fold))\n",
    "\n",
    "    # Save the model\n",
    "    model_save_path = f\"models/model_fold_{fold_no}.h5\"\n",
    "    model.save(model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_binary = (y_pred >= 0.5).astype(int)\n",
    "    accuracy = accuracy_score(Y_test, y_pred_binary)\n",
    "    acc_per_fold.append(accuracy)\n",
    "\n",
    "    fold_no += 1\n",
    "\n",
    "# Print accuracy for each fold\n",
    "for i, acc in enumerate(acc_per_fold, 1):\n",
    "    print(f'Accuracy for fold {i}: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case Ketika shuffle=True, random_state=123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 240 files belonging to 60 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-06 09:50:14.249856: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 465ms/step - accuracy: 0.0330 - loss: 0.9767 - val_accuracy: 0.0256 - val_loss: 0.1889\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 0.0652 - loss: 0.1677 - val_accuracy: 0.0000e+00 - val_loss: 0.1453\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 174ms/step - accuracy: 0.1930 - loss: 0.1157 - val_accuracy: 0.1538 - val_loss: 0.1323\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 0.4064 - loss: 0.0878 - val_accuracy: 0.3077 - val_loss: 0.1148\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - accuracy: 0.6002 - loss: 0.0559 - val_accuracy: 0.3846 - val_loss: 0.0959\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.7145 - loss: 0.0397 - val_accuracy: 0.4359 - val_loss: 0.0731\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 170ms/step - accuracy: 0.7871 - loss: 0.0262 - val_accuracy: 0.6154 - val_loss: 0.0589\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - accuracy: 0.9439 - loss: 0.0167 - val_accuracy: 0.6667 - val_loss: 0.0537\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 180ms/step - accuracy: 0.9413 - loss: 0.0124 - val_accuracy: 0.6923 - val_loss: 0.0442\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.9930 - loss: 0.0086 - val_accuracy: 0.7436 - val_loss: 0.0366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/model_fold_1.h5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
      "Training for fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 475ms/step - accuracy: 0.0113 - loss: 0.7254 - val_accuracy: 0.0000e+00 - val_loss: 0.2055\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - accuracy: 0.0656 - loss: 0.1668 - val_accuracy: 0.0000e+00 - val_loss: 0.1394\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 208ms/step - accuracy: 0.1795 - loss: 0.1266 - val_accuracy: 0.1026 - val_loss: 0.1337\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - accuracy: 0.3503 - loss: 0.1028 - val_accuracy: 0.1538 - val_loss: 0.1086\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 177ms/step - accuracy: 0.4268 - loss: 0.0665 - val_accuracy: 0.2821 - val_loss: 0.0861\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.7010 - loss: 0.0424 - val_accuracy: 0.4103 - val_loss: 0.0714\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - accuracy: 0.7784 - loss: 0.0308 - val_accuracy: 0.5128 - val_loss: 0.0633\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step - accuracy: 0.8597 - loss: 0.0227 - val_accuracy: 0.5385 - val_loss: 0.0511\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - accuracy: 0.9822 - loss: 0.0148 - val_accuracy: 0.6923 - val_loss: 0.0466\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 175ms/step - accuracy: 0.9765 - loss: 0.0129 - val_accuracy: 0.7436 - val_loss: 0.0441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/model_fold_2.h5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
      "Training for fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 485ms/step - accuracy: 0.0330 - loss: 0.8833 - val_accuracy: 0.0263 - val_loss: 0.1457\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - accuracy: 0.0646 - loss: 0.1512 - val_accuracy: 0.0789 - val_loss: 0.1540\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 180ms/step - accuracy: 0.1669 - loss: 0.1644 - val_accuracy: 0.2105 - val_loss: 0.1399\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 173ms/step - accuracy: 0.4072 - loss: 0.1130 - val_accuracy: 0.2895 - val_loss: 0.1178\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - accuracy: 0.5507 - loss: 0.0745 - val_accuracy: 0.4474 - val_loss: 0.0990\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - accuracy: 0.6956 - loss: 0.0450 - val_accuracy: 0.4737 - val_loss: 0.0933\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 168ms/step - accuracy: 0.7775 - loss: 0.0366 - val_accuracy: 0.5789 - val_loss: 0.0843\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - accuracy: 0.9432 - loss: 0.0189 - val_accuracy: 0.5789 - val_loss: 0.0791\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 170ms/step - accuracy: 0.9384 - loss: 0.0152 - val_accuracy: 0.6579 - val_loss: 0.0749\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - accuracy: 0.9627 - loss: 0.0117 - val_accuracy: 0.7368 - val_loss: 0.0720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/model_fold_3.h5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
      "Training for fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 469ms/step - accuracy: 0.0069 - loss: 0.7984 - val_accuracy: 0.0263 - val_loss: 0.1817\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 168ms/step - accuracy: 0.0798 - loss: 0.1632 - val_accuracy: 0.0789 - val_loss: 0.1441\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.2181 - loss: 0.1282 - val_accuracy: 0.1842 - val_loss: 0.1059\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - accuracy: 0.4983 - loss: 0.0850 - val_accuracy: 0.3158 - val_loss: 0.0775\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step - accuracy: 0.5858 - loss: 0.0622 - val_accuracy: 0.6053 - val_loss: 0.0465\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 181ms/step - accuracy: 0.7879 - loss: 0.0327 - val_accuracy: 0.6579 - val_loss: 0.0351\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - accuracy: 0.8686 - loss: 0.0233 - val_accuracy: 0.6579 - val_loss: 0.0303\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - accuracy: 0.9193 - loss: 0.0184 - val_accuracy: 0.8684 - val_loss: 0.0241\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - accuracy: 0.9636 - loss: 0.0115 - val_accuracy: 0.8947 - val_loss: 0.0219\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 171ms/step - accuracy: 0.9965 - loss: 0.0076 - val_accuracy: 0.8947 - val_loss: 0.0193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/model_fold_4.h5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
      "Training for fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 481ms/step - accuracy: 0.0078 - loss: 0.7799 - val_accuracy: 0.0526 - val_loss: 0.1339\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 176ms/step - accuracy: 0.0685 - loss: 0.1566 - val_accuracy: 0.1053 - val_loss: 0.1444\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - accuracy: 0.1726 - loss: 0.1431 - val_accuracy: 0.1316 - val_loss: 0.1273\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - accuracy: 0.3221 - loss: 0.1225 - val_accuracy: 0.2368 - val_loss: 0.0992\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 174ms/step - accuracy: 0.5503 - loss: 0.0744 - val_accuracy: 0.2895 - val_loss: 0.0714\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 0.6474 - loss: 0.0557 - val_accuracy: 0.4737 - val_loss: 0.0514\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - accuracy: 0.7931 - loss: 0.0368 - val_accuracy: 0.6579 - val_loss: 0.0400\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - accuracy: 0.8833 - loss: 0.0241 - val_accuracy: 0.7368 - val_loss: 0.0337\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - accuracy: 0.9462 - loss: 0.0164 - val_accuracy: 0.8684 - val_loss: 0.0321\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - accuracy: 0.9792 - loss: 0.0137 - val_accuracy: 0.8158 - val_loss: 0.0305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/model_fold_5.h5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2s/step\n",
      "Accuracy for fold 1: 0.5416666666666666\n",
      "Accuracy for fold 2: 0.5416666666666666\n",
      "Accuracy for fold 3: 0.6041666666666666\n",
      "Accuracy for fold 4: 0.75\n",
      "Accuracy for fold 5: 0.5208333333333334\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Load your image dataset and preprocessing here\n",
    "# Assume X is your image data and Y is your labels\n",
    "# Modify this part according to your image dataset loading and preprocessing\n",
    "\n",
    "# Define your image data (X) and labels (Y) here\n",
    "# Example: X = ... # Load images using some method (e.g., tf.keras.preprocessing.image_dataset_from_directory)\n",
    "X = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"dataset/data\",\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    color_mode='rgb',  # Mengatur mode warna menjadi grayscale\n",
    "    batch_size=32,\n",
    "    image_size=(52, 52),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    ")\n",
    "# Example: Y = ... # Load labels (may need to be encoded)\n",
    "def extract_labels(image, label):\n",
    "    return label\n",
    "\n",
    "# Map the dataset to extract labels\n",
    "Y = X.map(extract_labels)\n",
    "\n",
    "# Split data into train and test sets\n",
    "# Convert dataset to numpy arrays\n",
    "X_list = []\n",
    "Y_list = []\n",
    "for images, labels in X.as_numpy_iterator():\n",
    "    X_list.extend(images)\n",
    "    Y_list.extend(labels)\n",
    "X = np.array(X_list)\n",
    "Y = np.array(Y_list)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Convert labels to one-hot vectors\n",
    "Y_train = to_categorical(Y_train, num_classes=60)\n",
    "Y_test = to_categorical(Y_test, num_classes=60)\n",
    "\n",
    "# Define the ResNet50 model\n",
    "def build_resnet50_model():\n",
    "    # Membuat base model ResNet50 tanpa lapisan Fully Connected terakhir\n",
    "    base_model = ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(52, 52, 3),\n",
    "    )\n",
    "\n",
    "    # Menghentikan layer-layer yang ada pada base model agar tidak ter-update selama pelatihan\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Membangun model dengan menambahkan lapisan kustom di atas base model\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    predictions = Dense(60, activation='softmax')(x)\n",
    "\n",
    "    # Membuat model gabungan\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Initialize k-Fold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "# Execute K-fold cross-validation\n",
    "fold_no = 1\n",
    "acc_per_fold = [] # Save accuracy from each fold\n",
    "\n",
    "# Train the model for each split (fold)\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    print('Training for fold', fold_no)\n",
    "\n",
    "    # Get train and test data for this fold\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[test_index]\n",
    "    Y_train_fold, Y_val_fold = Y_train[train_index], Y_train[test_index]\n",
    "\n",
    "    # Build the model\n",
    "    model = build_resnet50_model()\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train_fold, Y_train_fold, epochs=10, validation_data=(X_val_fold, Y_val_fold))\n",
    "\n",
    "    # Save the model\n",
    "    model_save_path = f\"models/model_fold_{fold_no}.h5\"\n",
    "    model.save(model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_binary = (y_pred >= 0.5).astype(int)\n",
    "    accuracy = accuracy_score(Y_test, y_pred_binary)\n",
    "    acc_per_fold.append(accuracy)\n",
    "\n",
    "    fold_no += 1\n",
    "\n",
    "# Print accuracy for each fold\n",
    "for i, acc in enumerate(acc_per_fold, 1):\n",
    "    print(f'Accuracy for fold {i}: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 240 files belonging to 60 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-06 15:40:15.112750: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 375ms/step - accuracy: 0.0184 - loss: 0.8284 - val_accuracy: 0.0256 - val_loss: 0.1387\n",
      "Epoch 2/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 0.0602 - loss: 0.1548 - val_accuracy: 0.2308 - val_loss: 0.1244\n",
      "Epoch 3/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - accuracy: 0.2275 - loss: 0.1309 - val_accuracy: 0.2564 - val_loss: 0.1027\n",
      "Epoch 4/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - accuracy: 0.3926 - loss: 0.0872 - val_accuracy: 0.1538 - val_loss: 0.0957\n",
      "Epoch 5/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 0.5039 - loss: 0.0625 - val_accuracy: 0.3077 - val_loss: 0.0698\n",
      "Epoch 6/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 0.6972 - loss: 0.0416 - val_accuracy: 0.5128 - val_loss: 0.0602\n",
      "Epoch 7/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 0.8332 - loss: 0.0269 - val_accuracy: 0.5128 - val_loss: 0.0515\n",
      "Epoch 8/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - accuracy: 0.9133 - loss: 0.0214 - val_accuracy: 0.6667 - val_loss: 0.0427\n",
      "Epoch 9/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - accuracy: 0.9145 - loss: 0.0167 - val_accuracy: 0.6410 - val_loss: 0.0361\n",
      "Epoch 10/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.9521 - loss: 0.0126 - val_accuracy: 0.6923 - val_loss: 0.0385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/model_fold_1.h5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
      "Predicted Classes: [30 37 47 58 28 13 14  2 55 52 26 37 56 23 13 22 33 37 20 49 14  3 52 59\n",
      " 13 19  3  0 48 31 58  3 13 13 17 44 53 26 13 36 24 16 32 35 40  3 30 44]\n",
      "True Classes: [30  9 47 58 28  6 14  2 55 52 26 36 11 23 13 22 33 12 50 49 14  8 38 59\n",
      "  9 19  3  0 48 31 50  3  6  9 17 44 53 38 13 36 24 16 32 35 40  8 30 51]\n",
      "Training for fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 380ms/step - accuracy: 0.0296 - loss: 1.0594 - val_accuracy: 0.0000e+00 - val_loss: 0.2111\n",
      "Epoch 2/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.0371 - loss: 0.1987 - val_accuracy: 0.0513 - val_loss: 0.1484\n",
      "Epoch 3/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 0.0738 - loss: 0.1535 - val_accuracy: 0.0769 - val_loss: 0.1361\n",
      "Epoch 4/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 0.2017 - loss: 0.1104 - val_accuracy: 0.0769 - val_loss: 0.1104\n",
      "Epoch 5/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 0.3966 - loss: 0.0798 - val_accuracy: 0.3077 - val_loss: 0.0911\n",
      "Epoch 6/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 0.5344 - loss: 0.0594 - val_accuracy: 0.3077 - val_loss: 0.0840\n",
      "Epoch 7/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 0.6139 - loss: 0.0501 - val_accuracy: 0.3846 - val_loss: 0.0678\n",
      "Epoch 8/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 0.8214 - loss: 0.0329 - val_accuracy: 0.5128 - val_loss: 0.0608\n",
      "Epoch 9/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - accuracy: 0.8515 - loss: 0.0270 - val_accuracy: 0.5641 - val_loss: 0.0568\n",
      "Epoch 10/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 0.8726 - loss: 0.0212 - val_accuracy: 0.6410 - val_loss: 0.0544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/model_fold_2.h5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
      "Predicted Classes: [30 37 47 37 28  6 14  2 55 52 30 57 11 23 37 22 33 37 50 49 14  8 37 59\n",
      " 37 37  3  0 48 31 50  3  6 37  3 44 53 44  4 37 37 16 55 35 40  8 30 31]\n",
      "True Classes: [30  9 47 58 28  6 14  2 55 52 26 36 11 23 13 22 33 12 50 49 14  8 38 59\n",
      "  9 19  3  0 48 31 50  3  6  9 17 44 53 38 13 36 24 16 32 35 40  8 30 51]\n",
      "Training for fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 375ms/step - accuracy: 0.0000e+00 - loss: 0.9411 - val_accuracy: 0.0000e+00 - val_loss: 0.1588\n",
      "Epoch 2/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - accuracy: 0.0423 - loss: 0.1556 - val_accuracy: 0.1053 - val_loss: 0.1476\n",
      "Epoch 3/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.1315 - loss: 0.1398 - val_accuracy: 0.1316 - val_loss: 0.1356\n",
      "Epoch 4/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.3480 - loss: 0.0981 - val_accuracy: 0.2895 - val_loss: 0.1201\n",
      "Epoch 5/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - accuracy: 0.5468 - loss: 0.0734 - val_accuracy: 0.3158 - val_loss: 0.1054\n",
      "Epoch 6/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 0.7148 - loss: 0.0453 - val_accuracy: 0.3947 - val_loss: 0.0878\n",
      "Epoch 7/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 0.8102 - loss: 0.0297 - val_accuracy: 0.4737 - val_loss: 0.0746\n",
      "Epoch 8/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.8481 - loss: 0.0248 - val_accuracy: 0.5000 - val_loss: 0.0700\n",
      "Epoch 9/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.9099 - loss: 0.0174 - val_accuracy: 0.5526 - val_loss: 0.0658\n",
      "Epoch 10/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 0.9545 - loss: 0.0125 - val_accuracy: 0.6842 - val_loss: 0.0587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/model_fold_3.h5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
      "Predicted Classes: [53 36 47 39 28  6 14  2 55 52 26 36 11 23 20 22 33 37 20 49 14  8 38 20\n",
      " 36 36 11  0 48 31  0 13  6 36 17 51 53 38 45 36 24 16 25 35 40 45 53 51]\n",
      "True Classes: [30  9 47 58 28  6 14  2 55 52 26 36 11 23 13 22 33 12 50 49 14  8 38 59\n",
      "  9 19  3  0 48 31 50  3  6  9 17 44 53 38 13 36 24 16 32 35 40  8 30 51]\n",
      "Training for fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 473ms/step - accuracy: 0.0028 - loss: 0.8050 - val_accuracy: 0.0526 - val_loss: 0.1588\n",
      "Epoch 2/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 0.0587 - loss: 0.1547 - val_accuracy: 0.0526 - val_loss: 0.1409\n",
      "Epoch 3/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 0.1530 - loss: 0.1324 - val_accuracy: 0.0789 - val_loss: 0.1220\n",
      "Epoch 4/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.3243 - loss: 0.0827 - val_accuracy: 0.3158 - val_loss: 0.0846\n",
      "Epoch 5/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - accuracy: 0.5268 - loss: 0.0593 - val_accuracy: 0.3947 - val_loss: 0.0595\n",
      "Epoch 6/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - accuracy: 0.6433 - loss: 0.0408 - val_accuracy: 0.5789 - val_loss: 0.0435\n",
      "Epoch 7/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - accuracy: 0.7603 - loss: 0.0312 - val_accuracy: 0.7368 - val_loss: 0.0348\n",
      "Epoch 8/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 0.8745 - loss: 0.0204 - val_accuracy: 0.7105 - val_loss: 0.0332\n",
      "Epoch 9/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - accuracy: 0.8861 - loss: 0.0170 - val_accuracy: 0.8158 - val_loss: 0.0335\n",
      "Epoch 10/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 0.9832 - loss: 0.0111 - val_accuracy: 0.8421 - val_loss: 0.0321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/model_fold_4.h5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
      "Predicted Classes: [30 13 47  9 28  6 14  2 55 52 26 37 11 23 45 22 33 37 50 49 14 42 38 59\n",
      " 13 19  3 32 48 10 50  3  6 13 17 44 53 38 13 27 24 16 32 35 40 40 30 51]\n",
      "True Classes: [30  9 47 58 28  6 14  2 55 52 26 36 11 23 13 22 33 12 50 49 14  8 38 59\n",
      "  9 19  3  0 48 31 50  3  6  9 17 44 53 38 13 36 24 16 32 35 40  8 30 51]\n",
      "Training for fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 375ms/step - accuracy: 0.0383 - loss: 0.8458 - val_accuracy: 0.0263 - val_loss: 0.1860\n",
      "Epoch 2/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.0573 - loss: 0.1656 - val_accuracy: 0.0789 - val_loss: 0.1608\n",
      "Epoch 3/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.2413 - loss: 0.1309 - val_accuracy: 0.1053 - val_loss: 0.1490\n",
      "Epoch 4/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - accuracy: 0.3570 - loss: 0.0971 - val_accuracy: 0.1053 - val_loss: 0.1171\n",
      "Epoch 5/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 0.4793 - loss: 0.0669 - val_accuracy: 0.4211 - val_loss: 0.0759\n",
      "Epoch 6/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - accuracy: 0.7056 - loss: 0.0420 - val_accuracy: 0.5263 - val_loss: 0.0567\n",
      "Epoch 7/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - accuracy: 0.7921 - loss: 0.0283 - val_accuracy: 0.4474 - val_loss: 0.0483\n",
      "Epoch 8/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 0.8920 - loss: 0.0196 - val_accuracy: 0.7105 - val_loss: 0.0408\n",
      "Epoch 9/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 0.9463 - loss: 0.0161 - val_accuracy: 0.7895 - val_loss: 0.0324\n",
      "Epoch 10/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.9808 - loss: 0.0109 - val_accuracy: 0.7895 - val_loss: 0.0290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/model_fold_5.h5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2s/step\n",
      "Predicted Classes: [30 37 47 58 28 39 14  2 55 52 26 37 11 23 13 22 33 46 50 49 14 29 10 59\n",
      " 13 19  3 12 48 31 50  3 39 37 17 44 53 38 37 37 21 16 32 35 40 45 30 51]\n",
      "True Classes: [30  9 47 58 28  6 14  2 55 52 26 36 11 23 13 22 33 12 50 49 14  8 38 59\n",
      "  9 19  3  0 48 31 50  3  6  9 17 44 53 38 13 36 24 16 32 35 40  8 30 51]\n",
      "Accuracy for fold 1: 0.6875\n",
      "Accuracy for fold 2: 0.6458333333333334\n",
      "Accuracy for fold 3: 0.625\n",
      "Accuracy for fold 4: 0.75\n",
      "Accuracy for fold 5: 0.7083333333333334\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# Load your image dataset and preprocessing here\n",
    "# Assume X is your image data and Y is your labels\n",
    "# Modify this part according to your image dataset loading and preprocessing\n",
    "\n",
    "# Define your image data (X) and labels (Y) here\n",
    "# Example: X = ... # Load images using some method (e.g., tf.keras.preprocessing.image_dataset_from_directory)\n",
    "X = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"dataset/data\",\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    color_mode='rgb',  # Mengatur mode warna menjadi grayscale\n",
    "    batch_size=30,\n",
    "    image_size=(52, 52),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    ")\n",
    "# Example: Y = ... # Load labels (may need to be encoded)\n",
    "def extract_labels(image, label):\n",
    "    return label\n",
    "\n",
    "# Map the dataset to extract labels\n",
    "Y = X.map(extract_labels)\n",
    "\n",
    "# Split data into train and test sets\n",
    "# Convert dataset to numpy arrays\n",
    "X_list = []\n",
    "Y_list = []\n",
    "for images, labels in X.as_numpy_iterator():\n",
    "    X_list.extend(images)\n",
    "    Y_list.extend(labels)\n",
    "X = np.array(X_list)\n",
    "Y = np.array(Y_list)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Convert labels to one-hot vectors\n",
    "Y_train = to_categorical(Y_train, num_classes=60)\n",
    "Y_test = to_categorical(Y_test, num_classes=60)\n",
    "\n",
    "# Define the ResNet50 model\n",
    "def build_resnet50_model():\n",
    "    # Membuat base model ResNet50 tanpa lapisan Fully Connected terakhir\n",
    "    base_model = ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(52, 52, 3),\n",
    "    )\n",
    "\n",
    "    # Menghentikan layer-layer yang ada pada base model agar tidak ter-update selama pelatihan\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Membangun model dengan menambahkan lapisan kustom di atas base model\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    predictions = Dense(60, activation='softmax')(x)\n",
    "\n",
    "    # Membuat model gabungan\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Initialize k-Fold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "# Execute K-fold cross-validation\n",
    "fold_no = 1\n",
    "acc_per_fold = [] # Save accuracy from each fold\n",
    "\n",
    "# Train the model for each split (fold)\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    print('Training for fold', fold_no)\n",
    "\n",
    "    # Get train and test data for this fold\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[test_index]\n",
    "    Y_train_fold, Y_val_fold = Y_train[train_index], Y_train[test_index]\n",
    "\n",
    "    # Build the model\n",
    "    model = build_resnet50_model()\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train_fold, Y_train_fold, batch_size=30, epochs=10, validation_data=(X_val_fold, Y_val_fold))\n",
    "\n",
    "    # Save the model\n",
    "    model_save_path = f\"models/model_fold_{fold_no}.h5\"\n",
    "    model.save(model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "    # # Evaluate the model\n",
    "    # y_pred = model.predict(X_test)\n",
    "    # y_pred_binary = (y_pred >= 0.5).astype(int)\n",
    "    # accuracy = accuracy_score(Y_test, y_pred_binary)\n",
    "    # acc_per_fold.append(accuracy)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    true_classes = np.argmax(Y_test, axis=1)\n",
    "    accuracy = accuracy_score(true_classes, y_pred_classes)\n",
    "    acc_per_fold.append(accuracy)\n",
    "\n",
    "    # Print predicted and true classes\n",
    "    print(\"Predicted Classes:\", y_pred_classes)\n",
    "    print(\"True Classes:\", true_classes)\n",
    "    \n",
    "    fold_no += 1\n",
    "\n",
    "# Print accuracy for each fold\n",
    "for i, acc in enumerate(acc_per_fold, 1):\n",
    "    print(f'Accuracy for fold {i}: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
